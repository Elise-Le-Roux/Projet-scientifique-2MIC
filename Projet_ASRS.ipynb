{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(\"./ASRS_data.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous n'utilisons pas le corpus entier mais un sous-ensemble de celui-ci car il est trop long (41 062 documents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_doc = 10000 # nombre de documents du corpus que l'on veut utiliser\n",
    "corpus = corpus.loc[0:nb_doc, \"Narrative\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Calcul du TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions pour le calcul du TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naif_regex_tokenize(text):\n",
    "    \"\"\"\n",
    "    This is a very naif way of tokenize a text. Just using the\n",
    "    regular expression \"[a-z]\" that will match any single word\n",
    "    in lowercase.\n",
    "    Returns a list with all the tokens.\n",
    "    \"\"\"\n",
    "    p = re.compile(\"[a-z]+\")\n",
    "    return p.findall(text.lower())\n",
    "\n",
    "def compute_tf(d):\n",
    "    \"\"\"\n",
    "    Compute the tf for a given document d.\n",
    "    The formula used is \n",
    "    \n",
    "        tf(t, d) = 0.5 + 0.5 * (count(t, d)/max(count(t',d) for t' in d))\n",
    "    \n",
    "    This prevents bias in longer documents.\n",
    "    \"\"\"\n",
    "    terms = pd.Series(naif_regex_tokenize(d))\n",
    "    term_counts = terms.value_counts()\n",
    "    max_tc = max(term_counts)\n",
    "    return 0.5 + 0.5 * (term_counts / max_tc)\n",
    "\n",
    "def compute_idf(D):\n",
    "    \"\"\"\n",
    "    The input D is a list of pandas.Series\n",
    "    having as each element, the term frequency \n",
    "    computed by the function compute_tf.\n",
    "    \"\"\"\n",
    "    N = len(D)\n",
    "    all_terms = pd.concat(D)\n",
    "    nt = all_terms.index.value_counts() # The number of documents containing the term \"t\"\n",
    "    return np.log(N / nt)\n",
    "\n",
    "def compute_tf_idf_document(tf_document, idf):\n",
    "    \"\"\"Compute the tf-idf for each term in a document of the corpus\n",
    "\n",
    "    Keyword arguments:\n",
    "    tf_document -- list with the frequency of each term inside the document\n",
    "    idf -- the idf value for each term in the corpus\n",
    "    \"\"\"\n",
    "    return tf_document * np.array([idf[i] for i in tf_document.index])\n",
    "    \n",
    "def compute_tf_idf_corpus(D):\n",
    "    \"\"\"Compute the tf-idf for each term in a corpus\n",
    "\n",
    "    Keyword arguments:\n",
    "    D -- pandas Series containing a collection of documents in text format\n",
    "    \n",
    "    returns\n",
    "        list of pandas Series containing the tf-idf(t, d, D) for each term\n",
    "        inside each document of the corpus D\n",
    "    \"\"\"\n",
    "    term_freq = [compute_tf(d) for d in D]\n",
    "    idf = compute_idf(term_freq)\n",
    "    return [compute_tf_idf_document(d, idf) for d in term_freq]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut obtenir la matrice des TF-IDF de chaque mot dans chaque document :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = compute_tf_idf_corpus(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis la liste des TF-IDF de chaque mot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_terms = pd.concat(tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation d'un dictionnaire de \"stop words\" (mots vides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons un dictionnaire de \"stop words\" afin de retirer les mots tels que \"and\", \"the\" ou encore \"him\" qui ne sont pas informatifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in stopwords.words('english'):\n",
    "    if i in all_terms:\n",
    "        all_terms.drop(index=[i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moyenne des TF-IDF de chaque mot et classement des mots par TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un mot peut apparaître dans plusieurs documents. Il peut donc être associer à plusieurs valeurs de TF-IDF en fonction des documents. Pour pouvoir classer les mots en fonction de leur TF-IDF on fait donc tout d'abord la moyenne de tout les TF-IDF pour chaque mot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tf_idf = all_terms.groupby(all_terms.index).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant classer les mots en fonction de la moyenne de leurs TF-IDF :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tf_idf = mean_tf_idf.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Dictionnaire des mots les plus informatifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On considère par exemple qu'un mot qui est présent dans plus de 10 documents différents et qui a une forte valeur de TF-IDF est informatif. La fonction suivante permet de générer un dictionnaire de mots informatifs à partir d'un corpus D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionnaire(D, lenght_dico, K):\n",
    "    dico=[]\n",
    "    \n",
    "    terms = []\n",
    "    for d in D:\n",
    "        terms += list(set(naif_regex_tokenize(d)))\n",
    "    nt = pd.Series(terms).value_counts() # Le nombre de documents contenant le terme \"t\"\n",
    "    \n",
    "    for i in sorted_tf_idf.index:                           # On ajoute dans le dictionnaire les mots apparaissant dans plus\n",
    "        if nt[i]>K and len(i)>1 and len(dico)<lenght_dico:  # de K documents et ayant le plus grand TF_IDF jusqu'à ce que le\n",
    "            dico.append(i)                                  # dictionnaire soit plein ou qu'il n'y ai plus de mots\n",
    "               \n",
    "    return dico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'exemple suivant on génère un dictionnaire contenant les mots présent dans plus de 10 documents et ayant une forte valeur de TF-IDF. La taille du dictionnaire est inférieure ou égale à 100 mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['heli', 'lbs', 'den', 'dca', 'atl', 'sid', 'flap', 'profile', 'temp', 'wt', 'lines', 'equipment', 'service', 'twin', 'zone', 'ft', 'instr', 'west', 'checklist', 'ice', 'members', 'boundary', 'rapid', 'forgot', 'log', 'rpts', 'listening', 'restrictions', 'subsequent', 'coast', 'opp', 'north', 'roger', 'adequate', 'signs', 'scattered', 'minor', 'ctled', 'mgr', 'strong', 'outbnd', 'man', 'mgmnt', 'sbnd', 'artcc', 'dfw', 'block', 'target', 'restr', 'release', 'move', 'suggest', 'feels', 'accept', 'vmc', 'unless', 'combined', 'permission', 'negative', 'anyone', 'dispatch', 'suddenly', 'idle', 'indicator', 'exactly', 'green', 'tstms', 'fire', 'white', 'months', 'commuter', 'ltt', 'parked', 'conflicting', 'break', 'rpting', 'unknown', 'cruising', 'bay', 'investigation', 'estimate', 'chief', 'sequence', 'transition', 'door', 'primary', 'leveling', 'sfo', 'twice', 'headed', 'serious', 'maneuver', 'proceeding', 'injuries', 'transponder', 'none', 'severe', 'cloud', 'tracon', 'angle', 'file', 'touch', 'trouble', 'monitor', 'miles', 'events', 'parking', 'moment', 'estimated', 'noise', 'provided', 'removed', 'ata', 'telephone', 'inop', 'training', 'range', 'apchs', 'unicom', 'possibility', 'intended', 'usually', 'slight', 'advisories', 'written', 'routine', 'terrain', 'process', 'terminal', 'xmissions', 'specific', 'threshold', 'comment', 'safely', 'released', 'confused', 'great', 'often', 'rolled', 'station', 'inadvertently', 'prop', 'needs', 'fbo', 'gone', 'hearing', 'expedite', 'red', 'instruments', 'tapes', 'amount', 'considered', 'plus', 'recall', 'increase', 'overhead', 'dangerous', 'ebnd', 'commercial', 'ceiling', 'climbed', 'says', 'indications', 'mention', 'published', 'knowing', 'mentioned', 'maybe', 'job', 'distracted', 'seconds', 'become', 'according', 'routing', 'tail', 'ie', 'legal', 'pushed', 'responsibility', 'engs', 'showing', 'descending', 'seeing', 'seem', 'state', 'verified', 'show', 'problems', 'requesting', 'led', 'thus', 'xponder', 'entry', 'suggested', 'accident', 'provide', 'unsafe', 'review', 'clearly', 'mil', 'subsequently', 'slowed', 'watch', 'wheel', 'appears', 'brakes', 'sun', 'rain', 'duty', 'flow', 'remaining', 'visible', 'discussion', 'view', 'cancelled', 'arriving', 'picked', 'wdb', 'dropped', 'tuned', 'leave', 'declared', 'airborne', 'asking', 'wbound', 'knowledge', 'progress', 'ever', 'original', 'ny', 'sent', 'deps', 'caught', 'crews', 'bank', 'person', 'determine', 'duties', 'performed', 'moderate', 'every', 'judgement', 'contributed', 'running', 'saying', 'ref', 'third', 'supposed', 'unusual', 'matter', 'placed', 'ready', 'reporter', 'maintained', 'vert', 'else', 'ord', 'obvious', 'actual', 'believed', 'attitude', 'completely', 'altimeter', 'minute', 'moved', 'answer', 'charts', 'moving', 'vicinity', 'towards', 'instruction', 'resulted', 'repeated', 'areas', 'prevented', 'pic', 'chking', 'executed', 'airline', 'certain', 'issue', 'previously', 'san', 'happen', 'handle', 'including', 'understood', 'fast', 'waiting', 'selected', 'handling', 'returning', 'corrected', 'imc', 'panel', 'major', 'city', 'indicating', 'lot', 'rapidly', 'answered', 'total', 'readback', 'accepted', 'early', 'causing', 'remember', 'student', 'confirm', 'window', 'briefing', 'checked', 'familiar', 'edge', 'voice', 'applied', 'based', 'descended', 'realize', 'numerous', 'clrncs', 'turb', 'increased', 'located', 'bad', 'seems', 'condition', 'agreed', 'directed', 'yes', 'reading', 'coord', 'advisory', 'notice', 'centerline', 'spotted', 'prox', 'minutes', 'arsa', 'radial', 'engine', 'changes', 'except', 'morning', 'longer', 'winds', 'hdof', 'monitoring', 'concern', 'power', 'turns', 'states', 'speed', 'starting', 'track', 'pointed', 'known', 'alts', 'corrective', 'kept', 'report', 'receive', 'thinking', 'hit', 'brought', 'obviously', 'rest', 'opinion', 'thereafter', 'delay', 'explained', 'mind', 'flts', 'initially', 'held', 'remained', 'planned', 'intentions', 'separation', 'closer', 'svc', 'visually', 'airspd', 'cannot', 'added', 'avoided', 'home', 'thing', 'complied', 'head', 'talk', 'two', 'practice', 'particular', 'max', 'extended', 'system', 'broke', 'code', 'accomplished', 'potential', 'encountered', 'verify', 'minimum', 'understand', 'things', 'reply', 'attempt', 'someone', 'fss', 'workload', 'period', 'arpts', 'extremely', 'open', 'scheduled', 'cabin', 'possibly', 'advise', 'perhaps', 'quickly', 'expected', 'learned', 'apparent', 'effect', 'want', 'calling', 'ident', 'approved', 'quite', 'across', 'run', 'worked', 'single', 'computer', 'actions', 'discussed', 'climbing', 'result', 'people', 'fpm', 'present', 'xx', 'hr', 'additional', 'parallel', 'location', 'board', 'indication', 'entire', 'violation', 'appropriate', 'days', 'equip', 'note', 'information', 'lax', 'depart', 'large', 'freqs', 'preflt', 'apched', 'check', 'occurrence', 'broken', 'autoplt', 'performance', 'neither', 'try', 'really', 'arrived', 'talked', 'fac', 'giving', 'sw', 'setting', 'nw', 'similar', 'xmission', 'reduced', 'non', 'yrs', 'especially', 'everything', 'small', 'se', 'manual', 'properly', 'fix', 'radios', 'restriction', 'switch', 'reached', 'whether', 'inside', 'current', 'flaps', 'forward', 'therefore', 'remain', 'personnel', 'inspection', 'per', 'data', 'yet', 'jet', 'actually', 'complete', 'allow', 'pulled', 'squawk', 'decision', 'cruise', 'sign', 'determined', 'entering', 'deviation', 'lgt', 'event', 'experienced', 'difficult', 'seat', 'ask', 'collision', 'enter', 'stay', 'shut', 'uneventful', 'top', 'proceed', 'pressure', 'hard', 'calls', 'allowed', 'active', 'heavy', 'number', 'poor', 'anything', 'always', 'receiving', 'hand', 'coms', 'chart', 'rwys', 'chklist', 'ok', 'tell', 'elected', 'main', 'concerned', 'order', 'pass', 'earlier', 'let', 'reported', 'straight', 'ramp', 'best', 'trning', 'etc', 'prevent', 'standard', 'look', 'instrument', 'path', 'ops', 'attempted', 'leveled', 'ne', 'future', 'expect', 'experience', 'secs', 'closed', 'taking', 'crossed', 'loss', 'available', 'lack', 'notified', 'tca', 'clouds', 'higher', 'questioned', 'min', 'seen', 'late', 'confusion', 'wind', 'question', 'slightly', 'night', 'past', 'safe', 'necessary', 'come', 'reaching', 'place', 'discovered', 'mistake', 'nav', 'coming', 'atis', 'miss', 'soon', 'follow', 'trip', 'taxiing', 'agl', 'holding', 'established', 'visibility', 'alert', 'sector', 'roll', 'smt', 'find', 'noted', 'hear', 'start', 'leaving', 'rather', 'assumed', 'almost', 'phone', 'directly', 'loc', 'reason', 'operation', 'warning', 'onto', 'mode', 'clbed', 'involved', 'initiated', 'confirmed', 'outside', 'distance', 'failure', 'along', 'something', 'gear', 'help', 'seemed', 'slow', 'operating', 'dest', 'climb', 'tried', 'txwy', 'least', 'followed', 'control', 'fuel', 'dsnded', 'getting', 'different', 'via', 'nothing', 'lower', 'cause', 'previous', 'rate', 'need', 'proper', 'say', 'vector', 'wing', 'xa', 'plane', 'intercept', 'needed', 'little', 'nose', 'probs', 'damage', 'gate', 'response', 'work', 'coplt', 'finally', 'mlg', 'showed', 'knew', 'might', 'direction', 'evasive', 'normally', 'without', 'talking', 'completed', 'keep', 'vectored', 'handed', 'immediate', 'probably', 'pattern', 'nm', 'vis', 'flown', 'case', 'give', 'became', 'departing', 'switched', 'front', 'failed', 'ahead', 'request', 'though', 'hrs', 'returned', 'dme', 'pwr', 'intxn', 'lcl', 'leg', 'toward', 'replied', 'lights', 'factor', 'taxied', 'responded', 'procs', 'filed', 'trying', 'contributing', 'supvr', 'changed', 'making', 'better', 'looking', 'happened', 'initial', 'emer', 'decided', 'position', 'vectors', 'spd', 'apching', 'taken', 'must', 'already', 'missed', 'inbnd', 'maint', 'many', 'route', 'eng', 'downwind', 'done', 'entered', 'problem', 'shortly', 'instead', 'safety', 'xing', 'continue', 'although', 'stopped', 'sys', 'wanted', 'return', 'factors', 'long', 'enough', 'com', 'type', 'chk', 'correct', 'far', 'part', 'stop', 'unable', 'sep', 'apparently', 'dsnding', 'aware', 'flew', 'observed', 'either', 'lost', 'indicated', 'visual', 'proc', 'wrong', 'passing', 'field', 'chked', 'away', 'attn', 'felt', 'airplane', 'able', 'last', 'line', 'arr', 'enrte', 'put', 'turning', 'ctlrs', 'realized', 'clr', 'full', 'second', 'good', 'base', 'proceeded', 'sure', 'instructions', 'ils', 'acknowledged', 'less', 'airspace', 'near', 'clbing', 'clear', 'air', 'caused', 'plan', 'cross', 'take', 'appeared', 'rpt', 'instructed', 'acr', 'think', 'like', 'end', 'much', 'behind', 'busy', 'dsnd', 'fl', 'fact', 'using', 'direct', 'conflict', 'hold', 'acn', 'supplemental', 'cockpit', 'required', 'read', 'looked', 'times', 'sight', 'btwn', 'sma', 'error', 'set', 'within', 'avoid', 'contacted', 'kts', 'side', 'msl', 'conditions', 'working', 'taxi', 'found', 'used', 'possible', 'pax', 'clock', 'next', 'rptr', 'occurred', 'change', 'stated', 'use', 'new', 'rpted', 'issued', 'low', 'may', 'plts', 'way', 'well', 'faa', 'day', 'got', 'know', 'several', 'began', 'assigned', 'even', 'feel', 'went', 'short', 'close', 'passed', 'informed', 'noticed', 'company', 'heard', 'light', 'land', 'ifr', 'high', 'departed', 'however', 'came', 'clb', 'wx', 'mins', 'fly', 'radio', 'action', 'crew', 'level', 'took', 'course', 'going', 'never', 'vor', 'prior', 'gave', 'landed', 'around', 'thought', 'requested', 'degs', 'believe', 'callback', 'radar', 'maintain', 'make', 'vfr', 'center', 'continued', 'upon', 'final', 'go', 'started', 'received', 'normal', 'pos', 'dscnt', 'revealed', 'info', 'since', 'capt', 'conversation', 'get', 'still', 'point', 'first', 'later', 'see', 'tkof', 'saw', 'prob', 'situation', 'call', 'atc', 'immediately', 'due', 'contact', 'given', 'another', 'gnd', 'advised', 'freq', 'dep', 'deg', 'area', 'incident', 'hdg', 'turned', 'one', 'following', 'flying', 'plt', 'twr', 'ctl', 'made', 'arpt', 'also', 'said', 'approx', 'lndg', 'clrnc', 'called', 'turn', 'left', 'right', 'back', 'asked', 'could', 'mi', 'told', 'tfc', 'ctlr', 'alt', 'clred', 'rwy', 'apch', 'us']\n"
     ]
    }
   ],
   "source": [
    "dico = dictionnaire(corpus, 1000, 170)\n",
    "print(dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise les termes du dictionnaire afin de créer, pour chaque document, un vecteur TF-IDF. Ce vecteur aura les valeurs du TF-IDF de chaqu'un des termes. Par exemple, si la liste de termes est [\"float\", \"genetic\", \"circular\"] et qu'on a 4 document. On doit produire une matrice de 4 lignes et 3 colonnes :\n",
    "```\n",
    "0.1 5.8 9\n",
    "4.7 1.0 3\n",
    "8.0 2.4 6.0\n",
    "0.3 9.1 3.2\n",
    "```   \n",
    "Ici, chaque ligne contient les valeurs de *tf-idf* de [\"float\", \"genetic\", \"circular\"] (dans cet ordre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(D,dico):\n",
    "    matrice = np.zeros((len(D),len(dico)))\n",
    "\n",
    "    tf_idf = compute_tf_idf_corpus(D)\n",
    "    \n",
    "    for d in range(len(D)):\n",
    "        text_to_list = naif_regex_tokenize(D[d])\n",
    "        for t in range(len(dico)):\n",
    "            if dico[t] in text_to_list:\n",
    "                matrice[d][t]=tf_idf[d][dico[t]]\n",
    "                \n",
    "    return matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice = vectorizer(corpus, dico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On transforme ensuite cette matrice en matrice creuse afin qu'elle prenne moins de place en mémoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "matrice_csr = sparse.csr_matrix(matrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant normaliser les lignes de cette matrice. Cette étape permet de meilleurs résultats pour l'algorithme des K-means qui va suivre.\n",
    "La norme 2 des vecteurs TF-IDF représentés par chaque ligne doit être 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.03755907 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.05518    0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.14080141 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "matrix_normalized = normalize(matrice_csr, norm='l2', axis=1)\n",
    "matrice_finale = matrix_normalized.toarray()\n",
    "print(matrice_finale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètre\n",
    "k=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(v1, v2):\n",
    "    \"\"\"\n",
    "    Compute the distance between v1 and v2\n",
    "    v1 and v2 are numpy arrays\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((v1-v2)**2))\n",
    "\n",
    "def assign(vectors, centers):\n",
    "    \"\"\"\n",
    "    assign each vector to the closest center.\n",
    "    vectors is a numpy matrix. We want to assign each\n",
    "    row to the closest center.\n",
    "    centers is a numpy matrix. Each row has a center\n",
    "    \n",
    "    returns a list of integers. \n",
    "    One value for each vector indicating the closest center\n",
    "    \"\"\"\n",
    "    groups = np.zeros(vectors.shape[0])\n",
    "    for i in range(len(groups)):\n",
    "        groups[i] = np.argmin(np.apply_along_axis(distance, 1, centers, vectors[i]))\n",
    "    return groups\n",
    "\n",
    "def compute_centers(vectors, groups):\n",
    "    \"\"\"\n",
    "    Compute the centers for each group of \n",
    "    vectors\n",
    "    vectors is a numpy matrix\n",
    "    groups is a list containing the assignments\n",
    "    of the vectors\n",
    "    \"\"\"\n",
    "    new_centers = np.zeros([int(max(groups)) + 1, vectors.shape[1]])\n",
    "    for i in range(int(max(groups)) + 1):\n",
    "        ix = np.where(groups==i)[0]\n",
    "        grp_members = vectors[ix, :]\n",
    "        new_centers[i] = grp_members.mean(0)\n",
    "    return new_centers\n",
    "\n",
    "def choose_first_centers(vectors, k):\n",
    "    \"\"\"\n",
    "    Select the first k centers for the begining of the\n",
    "    k-means algorithm\n",
    "    \"\"\"\n",
    "    ix = np.arange(0, vectors.shape[0])\n",
    "    np.random.shuffle(ix)\n",
    "    return vectors[ix[:k], :]\n",
    "\n",
    "def kmeans(vectors, k, max_iterations = 500):\n",
    "    \"\"\"\n",
    "    Naive implementation of k-means algorithm\n",
    "    \"\"\"\n",
    "    centers_list = []\n",
    "    centers = choose_first_centers(vectors, k)\n",
    "    centers_list.append(centers)\n",
    "    groups = assign(vectors, centers)\n",
    "    new_centers = compute_centers(vectors, groups)\n",
    "    centers_list.append(new_centers)\n",
    "    nb_iter = 0\n",
    "    while (np.sum(np.abs(centers - new_centers)) > 0) or (nb_iter > max_iterations):\n",
    "        centers = np.copy(new_centers)\n",
    "        groups = assign(vectors, centers)\n",
    "        new_centers = compute_centers(vectors, groups)\n",
    "        centers_list.append(new_centers)\n",
    "        nb_iter += 1\n",
    "    return new_centers, centers_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers, centers_list = kmeans(matrice_finale, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tri des documents en fonction du résultat de l'algorithme k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0    [1, 5, 11, 15, 16, 31, 33, 39, 42, 45, 49, 50,...\n",
      "cluster 1    [35, 37, 72, 106, 108, 137, 139, 141, 156, 181...\n",
      "cluster 2    [8, 9, 12, 18, 27, 32, 46, 57, 67, 83, 87, 95,...\n",
      "cluster 3    [17, 23, 43, 47, 60, 64, 66, 73, 91, 92, 93, 1...\n",
      "cluster 4    [0, 2, 3, 4, 41, 44, 61, 79, 81, 85, 98, 99, 1...\n",
      "cluster 5    [7, 10, 14, 20, 21, 36, 107, 126, 130, 159, 18...\n",
      "cluster 6    [30, 34, 40, 55, 65, 68, 75, 76, 82, 94, 100, ...\n",
      "cluster 7    [6, 13, 19, 22, 24, 25, 26, 28, 29, 38, 48, 53...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "Docs=[]                           # Création d'une série pandas contenant le numéro des documents associés à chaque cluster\n",
    "Index=[]\n",
    "for i in range(k):\n",
    "    Index += [\"cluster \"+str(i)]\n",
    "    Docs += [[]]\n",
    "tri=pd.Series(Docs,index=Index)\n",
    "\n",
    "Assign=assign(matrice_finale, centers) # Grâce à la fonction assign qui assigne chaque vecteur au centre le plus proche,\n",
    "for doc in range(len(Assign)):         # on remplit cette série  \n",
    "    for cluster in range(k):\n",
    "        if int(Assign[doc])==cluster:\n",
    "            Docs[cluster]+=[doc]\n",
    "\n",
    "print(tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BarContainer object of 8 artists>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nombre de documents par cluster\n",
    "import matplotlib.pyplot as plt\n",
    "taille=[]\n",
    "for i in tri.index:\n",
    "    taille+=[len(tri[i])]\n",
    "    \n",
    "print(plt.barh(tri.index, taille, color=\"skyblue\", edgecolor=\"black\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 : fl\n",
      "Cluster 1 : clock\n",
      "Cluster 2 : final\n",
      "Cluster 3 : gear\n",
      "Cluster 4 : vfr\n",
      "Cluster 5 : sector\n",
      "Cluster 6 : taxi\n",
      "Cluster 7 : maint\n"
     ]
    }
   ],
   "source": [
    "# Titre/Catégorie du cluster\n",
    "# Mot le plus représentatif du cluster (Mot avec le plus grand TF-IDF)\n",
    "\n",
    "c = 0\n",
    "for centre in centers:\n",
    "    indices=[i for i,x in enumerate(centre) if x==max(centre)]\n",
    "    print(\"Cluster\",c,\":\", dico[indices[0]])\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
